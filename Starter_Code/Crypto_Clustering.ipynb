{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and dependencies\n",
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt \n",
    "import plotly.express as px\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# Suppress FutureWarning messages\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a Pandas DataFrame\n",
    "df_market_data = pd.read_csv(\"Resources/crypto_market_data.csv\")\n",
    "\n",
    "# Strip any whitespace in column names\n",
    "df_market_data.columns = df_market_data.columns.str.strip()\n",
    "\n",
    "# Set index column to 'coin_id'\n",
    "df_market_data.set_index(\"coin_id\", inplace=True)\n",
    "\n",
    "# Display sample data\n",
    "df_market_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Dataframe index\n",
    "print(df_market_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_columns = df_market_data.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate summary statistics\n",
    "df_market_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Check the DataFrame data types\n",
    "df_market_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_market_data.isnull().sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot your data to see what's in your DataFrame\n",
    "df_market_data.hvplot.line(\n",
    "    width=800,\n",
    "    height=400,\n",
    "    rot=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_market_data.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Use the `StandardScaler()` module from scikit-learn to normalize the data from the CSV file. Scale all columns with numerical values.\n",
    "#Note: normalization using StandardScaler() transforms selected features into NumPy array\n",
    "\n",
    "market_data_scaled = StandardScaler().fit_transform(df_market_data[[\"price_change_percentage_24h\",\"price_change_percentage_7d\",\"price_change_percentage_14d\",\"price_change_percentage_30d\",\"price_change_percentage_60d\",\"price_change_percentage_200d\",\"price_change_percentage_1y\"]])\n",
    "\n",
    "# Diplay the first five rows of the scaled data\n",
    "market_data_scaled[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the scaled data\n",
    "df_market_data_scaled = pd.DataFrame(\n",
    "    market_data_scaled,\n",
    "    columns=[\"price_change_percentage_24h\",\"price_change_percentage_7d\",\"price_change_percentage_14d\",\"price_change_percentage_30d\",\"price_change_percentage_60d\",\"price_change_percentage_200d\",\"price_change_percentage_1y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(df_market_data_scaled) == pd.DataFrame:\n",
    "    print(\"df_market_data_scaled is a DataFrame\")\n",
    "else:\n",
    "    print(\"df_market_data_scaled is not a DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the crypto names from the original data\n",
    "#i.e., Create a 'coin_id' column in the df_market_data_scaled DataFrame using the index of the original df_market_data DataFrame\n",
    "df_market_data_scaled[\"coin_id\"] = df_market_data.index\n",
    "\n",
    "# Set the coinid column as index\n",
    "df_market_data_scaled = df_market_data_scaled.set_index(\"coin_id\")\n",
    "\n",
    "# Display sample data\n",
    "df_market_data_scaled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the Best Value for k Using the Original Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the number of k-values from 1 to 11\n",
    "\n",
    "k = list(range(1, 12))  \n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the inertia values\n",
    "inertia =[]\n",
    "\n",
    "OMP_NUM_THREADS=1\n",
    "\n",
    "# Create a for loop to compute the inertia with each possible value of k\n",
    "# Inside the loop:\n",
    "# 1. Create a KMeans model using the loop counter for the n_clusters\n",
    "# 2. Fit the model to the data using `df_market_data_scaled`\n",
    "# 3. Append the model.inertia_ to the inertia list\n",
    "\n",
    "for i in k:\n",
    "    k_model = KMeans(n_clusters=i, random_state=1)\n",
    "    k_model.fit(df_market_data_scaled)\n",
    "    inertia.append(k_model.inertia_)\n",
    "\n",
    "print(inertia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMP_NUM_THREADS=1\n",
    "\n",
    "# Create a dictionary with the data to plot the Elbow curve\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "\n",
    "# Create a DataFrame with the data to plot the Elbow curve\n",
    "df_elbow = pd.DataFrame(elbow_data)\n",
    "\n",
    "print(df_elbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot a line chart with all the inertia values computed with \n",
    "# the different values of k to visually identify the optimal value for k.\n",
    "\n",
    "df_elbow.hvplot.line(\n",
    "    x=\"k\", \n",
    "    y=\"inertia\", \n",
    "    title=\"Elbow Curve\", \n",
    "    xticks=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the following question: \n",
    "\n",
    "**Question:** What is the best value for `k`?\n",
    "\n",
    "**Answer:** Four is the best value for k. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Cryptocurrencies with K-means Using the Original Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model using the best value for k\n",
    "model = KMeans(n_clusters=4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(df_market_data_scaled) == pd.DataFrame:\n",
    "    print(\"df_market_data_scaled is a DataFrame\")\n",
    "else:\n",
    "    print(\"df_market_data_scaled is not a DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the K-Means model using the scaled data\n",
    "model.fit(df_market_data_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Predict the clusters to group the cryptocurrencies using the scaled data\n",
    "k_4 = model.predict(df_market_data_scaled)\n",
    "\n",
    "# Print the predictions\n",
    "print(k_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the resulting array of cluster values.\n",
    "# Use enumerate to iterate over array k_4 and retrieve row index and corresponding cluster value\n",
    "for index, cluster_value in enumerate(k_4):\n",
    "    print(f\"Row index: {index}, Cluster value: {cluster_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame\n",
    "df_market_data_scaled_predictions=df_market_data_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the length of k_4\n",
    "print(\"Length of k_4:\", len(k_4))\n",
    "\n",
    "# Check the first few values of k_4\n",
    "print(\"First few values of k_4:\", k_4[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the type of df_market_data_scaled_predictions\n",
    "print(\"Type of df_market_data_scaled_predictions:\", type(df_market_data_scaled_predictions))\n",
    "\n",
    "# If df_market_data_scaled_predictions is a NumPy array, convert it to a DataFrame\n",
    "if isinstance(df_market_data_scaled_predictions, np.ndarray):\n",
    "    df_market_data_scaled_predictions = pd.DataFrame(df_market_data_scaled_predictions)\n",
    "\n",
    "# Verify the column names in df_market_data_scaled_predictions\n",
    "print(\"Column names in df_market_data_scaled_predictions:\", df_market_data_scaled_predictions.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to the DataFrame with the predicted clusters\n",
    "df_market_data_scaled_predictions['crypto_cluster_4']=k_4\n",
    "\n",
    "# Display sample data\n",
    "df_market_data_scaled_predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assistance with syntax provided by chat gpt\n",
    "\n",
    "counts_by_unique_value = df_market_data_scaled_predictions['crypto_cluster_4'].value_counts()\n",
    "print(counts_by_unique_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot using hvPlot by setting \n",
    "# `x=\"price_change_percentage_24h\"` and `y=\"price_change_percentage_7d\"`. \n",
    "# Color the graph points with the labels found using K-Means and \n",
    "# add the crypto name in the `hover_cols` parameter to identify \n",
    "# the cryptocurrency represented by each data point.\n",
    "\n",
    "# Create new DataFrame with index included as column\n",
    "df_market_data_scaled_predictions_with_index = df_market_data_scaled_predictions.reset_index()\n",
    "\n",
    "# Create the scatter plot with hover data including 'coin_id'\n",
    "fig = px.scatter(df_market_data_scaled_predictions_with_index, \n",
    "                 x='price_change_percentage_24h', \n",
    "                 y='price_change_percentage_7d', \n",
    "                 color='crypto_cluster_4', \n",
    "                 hover_data=['coin_id', 'crypto_cluster_4'], \n",
    "                 color_continuous_scale='viridis')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Scatter Plot of Cluster Assignments with Scaled Data', \n",
    "                  xaxis_title='price_change_percentage_24h', \n",
    "                  yaxis_title='price_change_percentage_7d', \n",
    "                  coloraxis_colorbar=dict(title='Cluster'))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize Clusters with Principal Component Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the PCA module\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA model instance and set `n_components=3`.\n",
    "pca = PCA(n_components=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the PCA model with `fit_transform` to reduce to three principal components.\n",
    "market_data_scaled_pca = pca.fit_transform(df_market_data_scaled)\n",
    "\n",
    "if type(market_data_scaled_pca) == pd.DataFrame:\n",
    "    print(\"market_data_scaled_pca is a DataFrame\")\n",
    "else:\n",
    "    print(\"market_data_scaled_pca is not a DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame with the PCA data\n",
    "df_market_data_scaled_pca = pd.DataFrame(market_data_scaled_pca)\n",
    "\n",
    "# Assign new column names\n",
    "df_market_data_scaled_pca.columns = ['PC1', 'PC2', 'PC3'] \n",
    "\n",
    "# View the first five rows of the DataFrame. \n",
    "df_market_data_scaled_pca[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_columns = df_market_data_scaled_pca.shape\n",
    "\n",
    "print(\"Number of rows:\", num_rows)\n",
    "print(\"Number of columns:\", num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the explained variance to determine how much information can be attributed to each principal component.\n",
    "\n",
    "# Calculate the PCA explained variance ratio\n",
    "pca.explained_variance_ratio_\n",
    "\n",
    "# total explained variance\n",
    "total_explained_variance = sum(pca.explained_variance_ratio_)\n",
    "\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"Total explained variance:\", total_explained_variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the following question: \n",
    "\n",
    "**Question:** What is the total explained variance of the three principal components?\n",
    "\n",
    "**Answer:** PC1 explains 37%, PC2 explains 35%, and PC3 explains 18% of the variance. The total explained variance is 89.5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_market_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the crypto names from the original data\n",
    "#i.e., Create a 'coin_id' column in the df_market_data_scaled_pca DataFrame using the index of the original df_market_data DataFrame\n",
    "df_market_data_scaled_pca[\"coin_id\"] = df_market_data.index\n",
    "\n",
    "# Set the coinid column as index\n",
    "df_market_data_scaled_pca = df_market_data_scaled_pca.set_index(\"coin_id\")\n",
    "\n",
    "# Display sample data\n",
    "df_market_data_scaled_pca.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the Best Value for k Using the PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list with the number of k-values from 1 to 11\n",
    "k = list(range(1, 11))  \n",
    "\n",
    "print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the inertia values\n",
    "inertia_pca= []\n",
    "\n",
    "# Create a for loop to compute the inertia with each possible value of k\n",
    "for i in k:\n",
    "    k_model = KMeans(n_clusters=i, random_state=1)\n",
    "    k_model.fit(df_market_data_scaled_pca)\n",
    "    inertia_pca.append(k_model.inertia_)\n",
    "\n",
    "# Inside the loop:\n",
    "# 1. Create a KMeans model using the loop counter for the n_clusters\n",
    "# 2. Fit the model to the data using `df_market_data_pca` (i.e., pca_df)\n",
    "# 3. Append the model.inertia_ to the inertia list\n",
    "\n",
    "print(inertia_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with the data to plot the Elbow curve\n",
    "pca_elbow_data = {\"k\": k, \"inertia\": inertia_pca}\n",
    "\n",
    "# Create a DataFrame with the data to plot the Elbow curve\n",
    "df_elbow_pca = pd.DataFrame(pca_elbow_data)\n",
    "\n",
    "print(df_elbow_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a line chart with all the inertia values computed with the different values of k to visually identify the optimal value for k.\n",
    "\n",
    "df_elbow_pca.hvplot.line(\n",
    "    x=\"k\", \n",
    "    y=\"inertia\", \n",
    "    title=\"Elbow Curve\", \n",
    "    xticks=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the following questions: \n",
    "\n",
    "* **Question:** What is the best value for `k` when using the PCA data?\n",
    "\n",
    "  * **Answer:** The best value for 'k' is still 4, based on the new elbow curve. \n",
    "\n",
    "\n",
    "* **Question:** Does it differ from the best k value found using the original data?\n",
    "\n",
    "  * **Answer:** It does not differ from the best k value found using the original data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster Cryptocurrencies with K-means Using the PCA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the K-Means model using the best value for k\n",
    "model = KMeans(n_clusters=4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the K-Means model using the PCA data\n",
    "model.fit(df_market_data_scaled_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the clusters to group the cryptocurrencies using the PCA data\n",
    "k_4 = model.predict(df_market_data_scaled_pca)\n",
    "\n",
    "# Print the resulting array of cluster values.\n",
    "print(k_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, cluster_value in enumerate(k_4):\n",
    "    print(f\"Row index: {index}, Cluster value: {cluster_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if type(df_market_data_scaled_pca) == pd.DataFrame:\n",
    "    print(\"df_market_data_scaled_pca is a DataFrame\")\n",
    "else:\n",
    "    print(\"df_market_data_scaled_pca is not a DataFrame\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the DataFrame with the PCA data\n",
    "df_market_data_scaled_pca_predict = pd.DataFrame(df_market_data_scaled_pca).copy()\n",
    "\n",
    "# Add a new column to the DataFrame with the predicted clusters\n",
    "df_market_data_scaled_pca_predict['crypto_cluster_4']=k_4\n",
    "\n",
    "df_market_data_scaled_pca_predict.columns = ['PC1', 'PC2', 'PC3', 'crypto_cluster_4'] \n",
    "\n",
    "# Display sample data\n",
    "df_market_data_scaled_pca_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a scatter plot using hvPlot by setting \n",
    "# `x=\"PC1\"` and `y=\"PC2\"`. \n",
    "# Color the graph points with the labels found using K-Means and \n",
    "# add the crypto name in the `hover_cols` parameter to identify the cryptocurrency represented by each data point.\n",
    "\n",
    "# Create new DataFrame with index included as column\n",
    "df_market_data_scaled_pca_predict_with_index = df_market_data_scaled_pca_predict.reset_index()\n",
    "\n",
    "# Create the scatter plot with hover data including 'coin_id'\n",
    "fig = px.scatter(df_market_data_scaled_pca_predict_with_index, \n",
    "                 x='PC1', \n",
    "                 y='PC2', \n",
    "                 color='crypto_cluster_4', \n",
    "                 hover_data=['coin_id', 'crypto_cluster_4'], \n",
    "                 color_continuous_scale='viridis')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(title='Scatter Plot of Cluster Assignments with Scaled Data and PCA', \n",
    "                  xaxis_title='PC1', \n",
    "                  yaxis_title='PC2', \n",
    "                  coloraxis_colorbar=dict(title='Cluster'))\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize and Compare the Results\n",
    "\n",
    "In this section, you will visually analyze the cluster analysis results by contrasting the outcome with and without using the optimization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Composite plot to contrast the Elbow curves\n",
    "#ChatGPT assisted with how to plot two curves side by side\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# df_elbow and df_elbow_pca contain inertia values for two data sets\n",
    "# Create new figure and set of subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "# Plot first Elbow curve\n",
    "ax1.plot(df_elbow['k'], df_elbow['inertia'], marker='o', linestyle='-', label='Original Data')\n",
    "ax1.set_title('Elbow Curve for Original Data')\n",
    "ax1.set_xlabel('Number of Clusters (k)')\n",
    "ax1.set_ylabel('Inertia')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot second Elbow curve\n",
    "ax2.plot(df_elbow_pca['k'], df_elbow_pca['inertia'], marker='s', linestyle='--', label='PCA Data')\n",
    "ax2.set_title('Elbow Curve for PCA Data')\n",
    "ax2.set_xlabel('Number of Clusters (k)')\n",
    "ax2.set_ylabel('Inertia')\n",
    "ax2.legend()\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Display composite plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_market_data_scaled_predictions.columns)\n",
    "print(df_market_data_scaled_pca_predict.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composite plot to contrast the clusters\n",
    "#ChatGPT assisted with how to plot two curves side by side and create hover data\n",
    "\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Create the scatter plot with hover data including 'coin_id'\n",
    "fig1 = px.scatter(df_market_data_scaled_predictions_with_index, \n",
    "                 x='price_change_percentage_24h', \n",
    "                 y='price_change_percentage_7d', \n",
    "                 color='crypto_cluster_4', \n",
    "                 hover_data=['coin_id', 'crypto_cluster_4'], \n",
    "                 color_continuous_scale='viridis')\n",
    "\n",
    "# Update layout\n",
    "fig1.update_layout(title='Scatter Plot of Cluster Assignments with Scaled Data', \n",
    "                  xaxis_title='price_change_percentage_24h', \n",
    "                  yaxis_title='price_change_percentage_7d', \n",
    "                  coloraxis_colorbar=dict(title='Cluster'))\n",
    "\n",
    "# Create the scatter plot with hover data including 'coin_id'\n",
    "fig2 = px.scatter(df_market_data_scaled_pca_predict_with_index, \n",
    "                 x='PC1', \n",
    "                 y='PC2', \n",
    "                 color='crypto_cluster_4', \n",
    "                 hover_data=['coin_id', 'crypto_cluster_4'], \n",
    "                 color_continuous_scale='viridis')\n",
    "\n",
    "# Update layout\n",
    "fig2.update_layout(title='Scatter Plot of Cluster Assignments with Scaled Data and PCA', \n",
    "                  xaxis_title='PC1', \n",
    "                  yaxis_title='PC2', \n",
    "                  coloraxis_colorbar=dict(title='Cluster'))\n",
    "\n",
    "# Combine the two plots into a side-by-side layout\n",
    "combined_fig = make_subplots(rows=1, cols=2, subplot_titles=('Cluster Chart 1: Scaled Data', 'Cluster Chart 2: Scaled Data with PCA'))\n",
    "\n",
    "# Add traces to the subplots\n",
    "combined_fig.add_trace(fig1.data[0], row=1, col=1)\n",
    "combined_fig.add_trace(fig2.data[0], row=1, col=2)\n",
    "\n",
    "# Update x-axis and y-axis labels for the first subplot\n",
    "combined_fig.update_xaxes(title_text=\"price_change_percentage_24h\", row=1, col=1)\n",
    "combined_fig.update_yaxes(title_text=\"price_change_percentage_7d\", row=1, col=1)\n",
    "\n",
    "# Update x-axis and y-axis labels for the second subplot\n",
    "combined_fig.update_xaxes(title_text=\"PC1\", row=1, col=2)\n",
    "combined_fig.update_yaxes(title_text=\"PC2\", row=1, col=2)\n",
    "\n",
    "# Update layout and show the combined plot\n",
    "combined_fig.update_layout(height=600, width=1000, showlegend=True, hovermode='closest', title=\"Combined Plots with Axes Labels\")\n",
    "combined_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the following question: \n",
    "\n",
    "  * **Question:** After visually analyzing the cluster analysis results, what is the impact of using fewer features to cluster the data using K-Means?\n",
    "\n",
    "  * **Answer:** When using fewer features, the four clusters are more defined than previously. In Cluster Chart 1, with the scaled data, the cluster zero plot looks like it could easily be a cluster 1 plot. The cluster 3 point looks like an outlier compared to the rest of the plots in the graph. In Cluster Chart 2, with the scaled data and PCA, cluster 2 and 0 are more tightly clustered but show some overlap. The cluster 3 plot again appears to be an outlier, although it's position on the graph has changed dramatically. In this second chart, the cluster 1 plot is now an outlier. It no longer \"sits\" with cluster 0. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
